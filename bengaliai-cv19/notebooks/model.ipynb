{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mZLisftygLeh","colab_type":"code","outputId":"2c9cd948-6128-45e9-c519-04b350412350","executionInfo":{"status":"ok","timestamp":1583376297971,"user_tz":-540,"elapsed":28357,"user":{"displayName":"mqcmd196","photoUrl":"","userId":"12972245435235032541"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rb_d8tL9gR3J","colab_type":"code","outputId":"b8b291dd-d8db-4a89-dd92-2a9ac66bcb8b","executionInfo":{"status":"ok","timestamp":1583376300021,"user_tz":-540,"elapsed":1391,"user":{"displayName":"mqcmd196","photoUrl":"","userId":"12972245435235032541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mmi24bKkgsQo","colab_type":"code","outputId":"c12fa93e-ba42-46bf-ed81-81b52a5bae7f","executionInfo":{"status":"ok","timestamp":1581913592805,"user_tz":-540,"elapsed":1078,"user":{"displayName":"정범준","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBOM61BGwey2npNQfr0e2LCuA9eQMwGWK2paLHa=s64","userId":"01726864658215807628"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","from torchsummary import summary\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def try_gpu(e):\n","    if torch.cuda.is_available():\n","        return e.cuda()\n","    return e\n","\n","class model(nn.Module):\n","    def __init__(self):\n","        super(model, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.b1 = nn.BatchNorm2d(32, momentum=0.15)     \n","        self.pool = nn.MaxPool2d(2,2)\n","        self.conv5 = nn.Conv2d(32, 32, 5, padding=2)\n","        self.conv5_dropout = nn.Dropout(p=0.3)\n","\n","        self.conv6 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv7 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.conv8 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.conv9 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.b2 = nn.BatchNorm2d(64, momentum=0.15)\n","        # self.pool = nn.MaxPool2d(2,2) same as upper pool\n","        self.conv10 = nn.Conv2d(64, 64, 5, padding=2)\n","        self.b3 = nn.BatchNorm2d(64, momentum=0.15)\n","        self.conv10_dropout = nn.Dropout(p=0.3)\n","\n","        self.conv11 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.conv12 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.conv13 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.conv14 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.b4 = nn.BatchNorm2d(128, momentum=0.15)\n","        # self.pool = nn.MaxPool2d(2,2) same as upper pool\n","        self.conv15 = nn.Conv2d(128, 128, 5, padding=2)\n","        self.b5 = nn.BatchNorm2d(128, momentum=0.15)\n","        self.conv15_dropout = nn.Dropout(p=0.3)\n","\n","        self.conv16 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.conv17 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.conv18 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.conv19 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.b6 = nn.BatchNorm2d(256, momentum=0.15)\n","        # self.pool = nn.MaxPool2d(2,2) same as upper pool\n","        self.conv20 = nn.Conv2d(256, 256, 5, padding=2)\n","        self.b7 = nn.BatchNorm2d(256, momentum=0.15)\n","        self.conv20_dropout = nn.Dropout(p=0.3)\n","\n","        self.dense1 = nn.Linear(256*4*4, 1024)\n","        self.dense1_dropout = nn.Dropout(p=0.3) # +relu\n","        self.dense2 = nn.Linear(1024, 512) # +relu\n","\n","        self.head_root = nn.Linear(512, 168) # + softmax\n","        self.head_vowel = nn.Linear(512, 11) # + softmax\n","        self.head_consonant = nn.Linear(512, 7) # + softmax\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        x = self.pool(F.relu(self.b1(self.conv4(x))))\n","        x = F.relu(self.conv5(x))\n","        x = self.conv5_dropout(x)\n","        \n","        x = F.relu(self.conv6(x))\n","        x = F.relu(self.conv7(x))\n","        x = F.relu(self.conv8(x))\n","        x = self.pool(F.relu(self.b2(self.conv9(x))))\n","        x = F.relu(self.b3(self.conv10(x)))\n","        x = self.conv10_dropout(x)\n","\n","        x = F.relu(self.conv11(x))\n","        x = F.relu(self.conv12(x))\n","        x = F.relu(self.conv13(x))\n","        x = self.pool(F.relu(self.b4(self.conv14(x))))\n","        x = F.relu(self.b5(self.conv15(x)))\n","        x = self.conv15_dropout(x)\n","\n","        x = F.relu(self.conv16(x))\n","        x = F.relu(self.conv17(x))\n","        x = F.relu(self.conv18(x))\n","        x = self.pool(F.relu(self.b6(self.conv19(x))))\n","        x = F.relu(self.b7(self.conv20(x)))\n","        x = self.conv20_dropout(x)\n","\n","        x = x.view(-1, 256*4*4)\n","        x = F.relu(self.dense1(x))\n","        x = F.relu(self.dense2(x))\n","        \n","        head_root = self.head_root(x)\n","        head_vowel = self.head_vowel(x)\n","        head_consonant = self.head_consonant(x)\n","\n","        return head_root, head_vowel, head_consonant # not sure..\n","\n","model = model()\n","model = try_gpu(model)\n","\n","criterion1 = nn.CrossEntropyLoss() \n","criterion2 = nn.CrossEntropyLoss() \n","criterion3 = nn.CrossEntropyLoss() \n","optimizer = optim.Adam(model.parameters())\n","\n","summary(model, (1, 64, 64))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 64, 64]             320\n","            Conv2d-2           [-1, 32, 64, 64]           9,248\n","            Conv2d-3           [-1, 32, 64, 64]           9,248\n","            Conv2d-4           [-1, 32, 64, 64]           9,248\n","       BatchNorm2d-5           [-1, 32, 64, 64]              64\n","         MaxPool2d-6           [-1, 32, 32, 32]               0\n","            Conv2d-7           [-1, 32, 32, 32]          25,632\n","           Dropout-8           [-1, 32, 32, 32]               0\n","            Conv2d-9           [-1, 64, 32, 32]          18,496\n","           Conv2d-10           [-1, 64, 32, 32]          36,928\n","           Conv2d-11           [-1, 64, 32, 32]          36,928\n","           Conv2d-12           [-1, 64, 32, 32]          36,928\n","      BatchNorm2d-13           [-1, 64, 32, 32]             128\n","        MaxPool2d-14           [-1, 64, 16, 16]               0\n","           Conv2d-15           [-1, 64, 16, 16]         102,464\n","      BatchNorm2d-16           [-1, 64, 16, 16]             128\n","          Dropout-17           [-1, 64, 16, 16]               0\n","           Conv2d-18          [-1, 128, 16, 16]          73,856\n","           Conv2d-19          [-1, 128, 16, 16]         147,584\n","           Conv2d-20          [-1, 128, 16, 16]         147,584\n","           Conv2d-21          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-22          [-1, 128, 16, 16]             256\n","        MaxPool2d-23            [-1, 128, 8, 8]               0\n","           Conv2d-24            [-1, 128, 8, 8]         409,728\n","      BatchNorm2d-25            [-1, 128, 8, 8]             256\n","          Dropout-26            [-1, 128, 8, 8]               0\n","           Conv2d-27            [-1, 256, 8, 8]         295,168\n","           Conv2d-28            [-1, 256, 8, 8]         590,080\n","           Conv2d-29            [-1, 256, 8, 8]         590,080\n","           Conv2d-30            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-31            [-1, 256, 8, 8]             512\n","        MaxPool2d-32            [-1, 256, 4, 4]               0\n","           Conv2d-33            [-1, 256, 4, 4]       1,638,656\n","      BatchNorm2d-34            [-1, 256, 4, 4]             512\n","          Dropout-35            [-1, 256, 4, 4]               0\n","           Linear-36                 [-1, 1024]       4,195,328\n","           Linear-37                  [-1, 512]         524,800\n","           Linear-38                  [-1, 168]          86,184\n","           Linear-39                   [-1, 11]           5,643\n","           Linear-40                    [-1, 7]           3,591\n","================================================================\n","Total params: 9,733,242\n","Trainable params: 9,733,242\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.02\n","Forward/backward pass size (MB): 11.01\n","Params size (MB): 37.13\n","Estimated Total Size (MB): 48.16\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-WDHxFdggtRN","colab_type":"code","colab":{}},"source":["# このセルはあとで変える\n","def train(model, epoch):\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        loss1 = criterion1(root_o, labels)\n","        loss2 = criterion2(vowel_o, labels)\n","        loss3 = criterion3(consonant_o, labels)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","        if i % 1000 == 0:\n","            print(\"epoch{} root {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss1.data))\n","            print(\"epoch{} vowel {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss2.data))\n","            print(\"epoch{} consonant {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss3.data))\n"," \n"," def test(model):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(head_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        total_r += root_l.size(0)\n","        correct_r += (root_pred == root_l).sum()\n","        total_v += vowel_l.size(0)\n","        correct_v += (vowel_pred == vowel_l).sum()\n","        total_c += consonant_l.size(0)\n","        correct_c += (consonant_pred == consonant_l).sum()\n","    print(\"root Accuracy {}/{} {:.2f}%\".format(correct_r, total_r, 100.0*correct_r/total_r))\n","    print(\"vowel Accuracy {}/{} {:.2f}%\".format(correct_v, total_v, 100.0*correct_v/total_v))\n","    print(\"consonant Accuracy {}/{} {:.2f}%\".format(correct_c, total_c, 100.0*correct_c/total_c))\n","    \n","for i in range(1,10):\n","    train(model, i)\n","    test(model)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9lgLwdIhARx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}