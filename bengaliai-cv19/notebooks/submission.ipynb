{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"submission.ipynb","provenance":[],"authorship_tag":"ABX9TyNdJ5Q8rtOmSDAQBNfe/w8f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ad778f05178a4f709f03e0f1fa78c3cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be8589260f78466bbe1e408b25f98ff8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c9a072a78e204f64b01200deb25628ee","IPY_MODEL_5aea3981e716492f960069119e8eeee4"]}},"be8589260f78466bbe1e408b25f98ff8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9a072a78e204f64b01200deb25628ee":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_73c0a0f9ea2f4e63b8e5288b954dc519","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":50210,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50210,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14e4f38fd38e44389d59d5814cf0a099"}},"5aea3981e716492f960069119e8eeee4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_201a644c4a7f4af69640645d2172bb30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 50210/50210 [00:58&lt;00:00, 855.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_78dc64d813aa4648afec60c9eed1c151"}},"73c0a0f9ea2f4e63b8e5288b954dc519":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14e4f38fd38e44389d59d5814cf0a099":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"201a644c4a7f4af69640645d2172bb30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"78dc64d813aa4648afec60c9eed1c151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a9e2cc74831440daeeef65904ea83d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fd087b3abe2b4fdaab2d2460eaee1686","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_145ca2699fd047ae88af684aa4a67c86","IPY_MODEL_4932ed72886648529948f15cbb3c59b9"]}},"fd087b3abe2b4fdaab2d2460eaee1686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"145ca2699fd047ae88af684aa4a67c86":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_86f64c8320994a3387005a6af3726525","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d6896b8d85a457294a37ce9ad1a7aca"}},"4932ed72886648529948f15cbb3c59b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30f0e73912b240778a3f4f727036e1dd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 1570/1570 [00:50&lt;00:00, 31.25it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df5d3788d695442c88424a3f5327e182"}},"86f64c8320994a3387005a6af3726525":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d6896b8d85a457294a37ce9ad1a7aca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30f0e73912b240778a3f4f727036e1dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"df5d3788d695442c88424a3f5327e182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed38cc9852fd48bea16c6c5e3f5a0e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_53669d5550764f36a82cfb8aec528074","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a72c35a3440e4975a9318598ee20f6b5","IPY_MODEL_712c9926a4e144be8087fbac581d5689"]}},"53669d5550764f36a82cfb8aec528074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a72c35a3440e4975a9318598ee20f6b5":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4685d0fc12e40a89de53f54b27932fa","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":50210,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50210,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e85b486d96414d82924a1bb0a85c4441"}},"712c9926a4e144be8087fbac581d5689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7512aa1a94be4627b867f7a78bb377ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 50210/50210 [01:03&lt;00:00, 787.11it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b872b96644e1445aa1c65390b5051013"}},"f4685d0fc12e40a89de53f54b27932fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e85b486d96414d82924a1bb0a85c4441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7512aa1a94be4627b867f7a78bb377ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b872b96644e1445aa1c65390b5051013":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"vXL01Cqx35dD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"878293d6-4365-4bec-be88-97d242331d88","executionInfo":{"status":"ok","timestamp":1582444583703,"user_tz":-540,"elapsed":545,"user":{"displayName":"정범준","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBOM61BGwey2npNQfr0e2LCuA9eQMwGWK2paLHa=s64","userId":"01726864658215807628"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WCVmBBxo_Pg9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pA1_Fdby4CO9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283,"referenced_widgets":["ad778f05178a4f709f03e0f1fa78c3cf","be8589260f78466bbe1e408b25f98ff8","c9a072a78e204f64b01200deb25628ee","5aea3981e716492f960069119e8eeee4","73c0a0f9ea2f4e63b8e5288b954dc519","14e4f38fd38e44389d59d5814cf0a099","201a644c4a7f4af69640645d2172bb30","78dc64d813aa4648afec60c9eed1c151","9a9e2cc74831440daeeef65904ea83d0","fd087b3abe2b4fdaab2d2460eaee1686","145ca2699fd047ae88af684aa4a67c86","4932ed72886648529948f15cbb3c59b9","86f64c8320994a3387005a6af3726525","5d6896b8d85a457294a37ce9ad1a7aca","30f0e73912b240778a3f4f727036e1dd","df5d3788d695442c88424a3f5327e182","ed38cc9852fd48bea16c6c5e3f5a0e7c","53669d5550764f36a82cfb8aec528074","a72c35a3440e4975a9318598ee20f6b5","712c9926a4e144be8087fbac581d5689","f4685d0fc12e40a89de53f54b27932fa","e85b486d96414d82924a1bb0a85c4441","7512aa1a94be4627b867f7a78bb377ca","b872b96644e1445aa1c65390b5051013"]},"outputId":"788ab4ce-cf62-4d21-b1fc-6e293cc1ea92"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","from tqdm.auto import tqdm\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","from torchsummary import summary\n","import gc\n","\n","dataset_dir = '../dataset'\n","train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')\n","\n","# 前処理を関数にまとめた\n","def resize(X, out_height=64, out_width=64):\n","  print('Resizing raw image... / 前処理実行中…')\n","  resized = {} # 前処理された画像が格納されるリスト\n","\n","  for i in tqdm(range(len(X))):\n","    image = X.iloc[[i]].values.reshape(HEIGHT, WIDTH)\n","    _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","    left = 1000\n","    right = -1\n","    top = 1000\n","    bottom = -1\n","\n","    for cnt in contours:\n","      x,y,w,h = cv2.boundingRect(cnt)\n","      left = min(x, left)\n","      right = max(x+w, right)\n","      top = min(y, top)\n","      bottom = max(y+h, bottom)\n","\n","    roi = image[top:bottom, left:right]\n","    resized_roi = cv2.resize(roi, (out_height, out_width),interpolation=cv2.INTER_AREA)\n","    resized[i] = resized_roi.reshape(-1)\n","\n","  # print(len(resized))\n","  \n","  return resized\n","\n","# PyTorch式のデータセットクラスを定義\n","\n","class MyDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, X, Y, transform=None):\n","        self.transform = transform\n","        self.X = X\n","        self.Y = Y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        out_data = self.X[idx].reshape(1,64,64)\n","        out_data = torch.tensor(out_data, dtype=torch.float)\n","\n","        #root_label = torch.tensor(self.Y[0][idx], dtype=torch.long)\n","        #vowel_label = torch.tensor(self.Y[1][idx], dtype=torch.long)\n","        #cons_label = torch.tensor(self.Y[2][idx], dtype=torch.long)\n","\n","        root_label = torch.tensor(np.argmax(self.Y[0][idx]), dtype=torch.long)\n","        vowel_label = torch.tensor(np.argmax(self.Y[1][idx]), dtype=torch.long)\n","        cons_label = torch.tensor(np.argmax(self.Y[2][idx]), dtype=torch.long)\n","\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","\n","        return out_data, root_label, vowel_label, cons_label\n","\n","def try_gpu(e):\n","    if torch.cuda.is_available():\n","        return e.cuda()\n","    return e\n","\n","class model(nn.Module):\n","    def __init__(self):\n","        super(model, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.b1 = nn.BatchNorm2d(32, momentum=0.15)     \n","        self.pool = nn.MaxPool2d(2,2)\n","        self.conv5 = nn.Conv2d(32, 32, 5, padding=2)\n","        self.conv5_dropout = nn.Dropout(p=0.3)\n","\n","        self.conv6 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv7 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.conv8 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.conv9 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.b2 = nn.BatchNorm2d(64, momentum=0.15)\n","        # self.pool = nn.MaxPool2d(2,2) same as upper pool\n","        self.conv10 = nn.Conv2d(64, 64, 5, padding=2)\n","        self.b3 = nn.BatchNorm2d(64, momentum=0.15)\n","        self.conv10_dropout = nn.Dropout(p=0.3)\n","\n","        self.conv11 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.conv12 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.conv13 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.conv14 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.b4 = nn.BatchNorm2d(128, momentum=0.15)\n","        # self.pool = nn.MaxPool2d(2,2) same as upper pool\n","        self.conv15 = nn.Conv2d(128, 128, 5, padding=2)\n","        self.b5 = nn.BatchNorm2d(128, momentum=0.15)\n","        self.conv15_dropout = nn.Dropout(p=0.3)\n","\n","        self.conv16 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.conv17 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.conv18 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.conv19 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.b6 = nn.BatchNorm2d(256, momentum=0.15)\n","        # self.pool = nn.MaxPool2d(2,2) same as upper pool\n","        self.conv20 = nn.Conv2d(256, 256, 5, padding=2)\n","        self.b7 = nn.BatchNorm2d(256, momentum=0.15)\n","        self.conv20_dropout = nn.Dropout(p=0.3)\n","\n","        self.dense1 = nn.Linear(256*4*4, 1024)\n","        self.dense1_dropout = nn.Dropout(p=0.3) # +relu\n","        self.dense2 = nn.Linear(1024, 512) # +relu\n","\n","        self.head_root = nn.Linear(512, 168) # + softmax\n","        self.head_vowel = nn.Linear(512, 11) # + softmax\n","        self.head_consonant = nn.Linear(512, 7) # + softmax\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        x = self.pool(F.relu(self.b1(self.conv4(x))))\n","        x = F.relu(self.conv5(x))\n","        x = self.conv5_dropout(x)\n","        \n","        x = F.relu(self.conv6(x))\n","        x = F.relu(self.conv7(x))\n","        x = F.relu(self.conv8(x))\n","        x = self.pool(F.relu(self.b2(self.conv9(x))))\n","        x = F.relu(self.b3(self.conv10(x)))\n","        x = self.conv10_dropout(x)\n","\n","        x = F.relu(self.conv11(x))\n","        x = F.relu(self.conv12(x))\n","        x = F.relu(self.conv13(x))\n","        x = self.pool(F.relu(self.b4(self.conv14(x))))\n","        x = F.relu(self.b5(self.conv15(x)))\n","        x = self.conv15_dropout(x)\n","\n","        x = F.relu(self.conv16(x))\n","        x = F.relu(self.conv17(x))\n","        x = F.relu(self.conv18(x))\n","        x = self.pool(F.relu(self.b6(self.conv19(x))))\n","        x = F.relu(self.b7(self.conv20(x)))\n","        x = self.conv20_dropout(x)\n","\n","        x = x.view(-1, 256*4*4)\n","        x = F.relu(self.dense1(x))\n","        x = F.relu(self.dense2(x))\n","        \n","        head_root = self.head_root(x)\n","        head_vowel = self.head_vowel(x)\n","        head_consonant = self.head_consonant(x)\n","\n","        return head_root, head_vowel, head_consonant # not sure..\n","\n","model = model()\n","model = try_gpu(model)\n","\n","criterion1 = nn.CrossEntropyLoss() \n","#criterion2 = nn.CrossEntropyLoss() \n","#criterion3 = nn.CrossEntropyLoss() \n","optimizer = optim.Adam(model.parameters())\n","\n","def train(model, epoch, train_loader):\n","    model.train()\n","    print(f'Epoch number {epoch}')\n","    for i, data in enumerate(tqdm(train_loader), 0):\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        loss1 = criterion1(root_o, root_l)\n","        loss2 = criterion1(vowel_o, vowel_l)\n","        loss3 = criterion1(consonant_o, consonant_l)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","        # if i % 500 == 0:\n","        #     print(\"epoch{} root {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss1.data))\n","        #     print(\"epoch{} vowel {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss2.data))\n","        #     print(\"epoch{} consonant {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss3.data))\n","\n","def test(model, test_loader):\n","    model.eval()\n","    correct_r, correct_v, correct_c = 0, 0, 0\n","    total_r, total_v, total_c = 0, 0, 0\n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        \n","        root_o, vowel_o, consonant_o = model(inputs)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        total_r += root_l.size(0)\n","        correct_r += (root_pred == root_l).sum()\n","        total_v += vowel_l.size(0)\n","        correct_v += (vowel_pred == vowel_l).sum()\n","        total_c += consonant_l.size(0)\n","        correct_c += (consonant_pred == consonant_l).sum()\n","\n","def train(model, epoch, train_loader):\n","    model.train()\n","    print(f'Epoch number {epoch}')\n","    for i, data in enumerate(tqdm(train_loader), 0):\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        loss1 = criterion1(root_o, root_l)\n","        loss2 = criterion1(vowel_o, vowel_l)\n","        loss3 = criterion1(consonant_o, consonant_l)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","        # if i % 500 == 0:\n","        #     print(\"epoch{} root {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss1.data))\n","        #     print(\"epoch{} vowel {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss2.data))\n","        #     print(\"epoch{} consonant {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss3.data))\n","\n","def test(model, test_loader):\n","    model.eval()\n","    correct_r, correct_v, correct_c = 0, 0, 0\n","    total_r, total_v, total_c = 0, 0, 0\n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        \n","        root_o, vowel_o, consonant_o = model(inputs)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        total_r += root_l.size(0)\n","        correct_r += (root_pred == root_l).sum()\n","        total_v += vowel_l.size(0)\n","        correct_v += (vowel_pred == vowel_l).sum()\n","        total_c += consonant_l.size(0)\n","        correct_c += (consonant_pred == consonant_l).sum()\n","\n","# 訓練ループ / Training Loop\n","\n","# val_perc = 0.2  # validation set の割合（クロスバリデーション）\n","epochs = 4  # ここでepoch数変えること\n","\n","for parq_i in range(4):\n","  print('=============================')\n","  print(f'Parquet {parq_i} の訓練を開始')\n","\n","  train_df_with_img = pd.merge(pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)\n","\n","  HEIGHT = 137\n","  WIDTH = 236\n","\n","  X_train = train_df_with_img.drop(columns=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'])\n","\n","  X_train_resized = pd.DataFrame(resize(X_train)).T / 255.0   # 値を0~1におさめる\n","  X_train_resized = X_train_resized.values\n","\n","  # メモリ節約\n","  del X_train\n","\n","  # PyTorchのデータセットクラスを作る前に、ラベルの情報も整備\n","  # 1-of-K符号化とか、One Hot Encodingとか呼ばれる方法でラベルをつくる\n","\n","  # 注：　PyTorchでは、ラベルはOne Hotじゃなくて良いことが判明したので、結局 MyDataset で元のラベルに戻している\n","\n","  Y_train_root = pd.get_dummies(train_df_with_img['grapheme_root']).values\n","  Y_train_vowel = pd.get_dummies(train_df_with_img['vowel_diacritic']).values\n","  Y_train_cons = pd.get_dummies(train_df_with_img['consonant_diacritic']).values\n","\n","  Y_train = [Y_train_root, Y_train_vowel, Y_train_cons]\n","\n","  trainval_dataset = MyDataset(X_train_resized, Y_train)\n","\n","  n_samples = len(trainval_dataset)\n","  #train_size = int(len(trainval_dataset)*(1.0 - val_perc))\n","  #val_size = n_samples - train_size\n","  #print(f'train size: {train_size}, validation size: {val_size}')\n","\n","  #train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n","\n","  train_loader = DataLoader(dataset=trainval_dataset,\n","                          batch_size=32, shuffle=True, num_workers=4)\n","  #val_loader = DataLoader(dataset=val_dataset, batch_size=32, num_workers=0)\n","  \n","  for i in range(1,epochs+1):\n","    train(model, i, train_loader)\n","    #test(model, val_loader)\n","\n","  # メモリ節約\n","  del train_df_with_img\n","  #del train_dataset\n","  del train_loader\n","  gc.collect()\n","\n","\n","# 提出ファイルの準備\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","model_copy = copy.deepcopy(model)\n","\n","for parq_i in range(4):\n","  df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","  df_test_img.set_index('image_id', inplace=True)\n","\n","  X_test_resized = resize(df_test_img)\n","  X_test_resized = pd.DataFrame(X_test_resized).T / 255.0   # 値を0~1におさめる\n","  X_test_resized = X_test_resized.values.reshape(-1, 1, 64, 64)\n","\n","  test_inputs = torch.tensor(X_test_resized, dtype=torch.float)\n","  test_inputs = Variable(test_inputs)\n","  test_inputs = try_gpu(test_inputs)\n","\n","  root_o, vowel_o, consonant_o = model(test_inputs)\n","  root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","  if torch.cuda.is_available():\n","    root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","  \n","  root_pred, vowel_pred, consonant_pred = root_pred.numpy(), vowel_pred.numpy(), consonant_pred.numpy()\n","\n","  for k, id in enumerate(df_test_img.index.values):\n","    row_id.append(id+'_consonant_diacritic')\n","    target.append(consonant_pred[k])\n","    row_id.append(id+'_grapheme_root')\n","    target.append(root_pred[k])\n","    row_id.append(id+'_vowel_diacritic')\n","    target.append(vowel_pred[k])\n","\n","  gc.collect()\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","df_sample.to_csv('submission.csv',index=False)\n","df_sample.head(36)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["=============================\n","Parquet 0 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad778f05178a4f709f03e0f1fa78c3cf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch number 1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a9e2cc74831440daeeef65904ea83d0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=1570), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","=============================\n","Parquet 1 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed38cc9852fd48bea16c6c5e3f5a0e7c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QTH44Nr4DTPy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}