{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ensemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNgNjS1zMTPJnSY2lDRt3HI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"E6zaJbq1hRVP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"c2789cc9-2b2b-4e1d-873c-2678b223fd41","executionInfo":{"status":"ok","timestamp":1583727687150,"user_tz":-540,"elapsed":18636,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lco1QBlvhlkc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"866b894b-572e-4175-d9ba-41fb8b884f9c","executionInfo":{"status":"ok","timestamp":1583727693398,"user_tz":-540,"elapsed":6230,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["!pip install efficientnet_pytorch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=9b2380f1ebcacb788cf3f3cb507472dba7c252bcc82dbdc4073ff1a9c029bfb1\n","  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F4FecSR0hql9","colab_type":"code","colab":{}},"source":["## 諸々の import\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","import torchvision.models as models\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","import PIL\n","import gc\n","\n","\n","from preprocess import *\n","\n","\n","import model.CNN as CNN\n","import model.efficientnet as efficientnet\n","import model.resnet18 as resnet18\n","import model.resnet34 as resnet34\n","import model.resnet50 as resnet50\n","import model.resnet101 as resnet101\n","import model.resnet152 as resnet152"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EuX-Nfuchs0y","colab_type":"code","colab":{}},"source":["## Parameters\n","\n","# resize後のサイズ\n","HEIGHT = 64\n","WIDTH = 64\n","\n","# 画像を3次元にするかどうか（EfficientNetなどを使うときはTrue）\n","# enable_3d = True\n","# ResNetとEfficientNetしか使わないので、常にTrueを想定する\n","\n","# True なら submission.csv を生成する\n","create_submission = False\n","\n","#Kaggleで提出するときはTrueにする\n","kaggle_flag = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-OyavFCiD9b","colab_type":"code","colab":{}},"source":["if kaggle_flag:\n","    dataset_dir = '/kaggle/input/bengaliai-cv19'\n","    model_dir = '/kaggle/input/trained_models'\n","else:\n","    dataset_dir = '../dataset'\n","    model_dir = '../trained_models'\n","\n","train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"surhOZ35j-gh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d0460a58-a31b-4f6d-d968-50368f92a3da","executionInfo":{"status":"ok","timestamp":1583746921673,"user_tz":-540,"elapsed":1151,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["model1 = resnet18.model()\n","model2 = efficientnet.model()\n","\n","\n","ensemble = [\n","    {\n","        'model': model1,\n","        'file': 'resnet18.pth',\n","        'w_grapheme': 0.30,\n","        'w_vowel': 0.30,\n","        'w_consonant': 0.30\n","    },\n","    {\n","        'model': model2,\n","        'file': 'efficientnet_28epoch.pth',\n","        'w_grapheme': 0.70,\n","        'w_vowel': 0.70,\n","        'w_consonant': 0.70\n","    }\n","]"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DvFakYtVrjZj","colab_type":"code","colab":{}},"source":["# テスト用のDataset, DataLoaderを作りたい\n","\n","class TestDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, X, transform=None, H=64, W=64):\n","        self.transform = transform\n","        self.X = X\n","        self.H = H \n","        self.W = W \n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","\n","        out_data = cv2.resize(self.X[idx].reshape(self.H, self.W), (224, 224), interpolation=cv2.INTER_AREA)\n","        out_data = out_data.reshape(224, 224, 1).astype(np.uint8)\n","        out_data = cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB)\n","        out_data = np.transpose(out_data, (2,0,1)) / 255.0\n","        out_data = out_data.reshape(3,224,224) \n","        \n","        out_data = torch.tensor(out_data, dtype=torch.float)\n","\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","\n","        return out_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dgpYRS5iH56","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"408d19d5-a1e9-457e-9d63-32376069aef6","executionInfo":{"status":"ok","timestamp":1583746932631,"user_tz":-540,"elapsed":11688,"user":{"displayName":"Ryo Terajima","photoUrl":"","userId":"06768188657916272381"}}},"source":["## 提出ファイルの作成\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","for parq_i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","    # df_test_img = pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet') # Error Check!\n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test_resized = resize(df_test_img, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8)\n","\n","    parq_size = len(df_test_img)\n","    pred_r = [None] * parq_size\n","    pred_v = [None] * parq_size\n","    pred_c = [None] * parq_size\n","    \n","    index = 0\n","    id_names = df_test_img.index.values\n","\n","    test_dataset = TestDataset(X_test_resized, H=HEIGHT, W=WIDTH)\n","    test_loader = DataLoader(test_dataset, batch_size=64, num_workers=0)\n","\n","    for data in test_loader:\n","        data = Variable(data)\n","        data = try_gpu(data)\n","\n","        bs = len(data)\n","        root_ens, vowel_ens, consonant_ens = np.zeros((bs, 168)), np.zeros((bs, 11)), np.zeros((bs, 7))\n","        # ens = ensembleの意味を込めて\n","\n","        for M in ensemble:\n","            device = torch.device('cpu')\n","            model = M['model']\n","            model.load_state_dict(torch.load(model_dir + '/' + M['file'], map_location=device))\n","            model = try_gpu(model)\n","            print(\"model loaded from {}\".format(model_dir + '/' + M['file']))\n","\n","            root_o, vowel_o, consonant_o = model(data)\n","            root_ens += M['w_grapheme'] * root_o.data.numpy()\n","            vowel_ens += M['w_vowel'] * vowel_o.data.numpy()\n","            consonant_ens += M['w_consonant'] * consonant_o.data.numpy()\n","\n","        root_pred, vowel_pred, consonant_pred = np.argmax(root_ens, axis=1), np.argmax(vowel_ens, axis=1), np.argmax(consonant_ens, axis=1)\n","\n","        for i in range(bs):\n","            row_id.append(id_names[index]+'_consonant_diacritic')\n","            target.append(consonant_pred[i])\n","            row_id.append(id_names[index]+'_grapheme_root')\n","            target.append(root_pred[i])\n","            row_id.append(id_names[index]+'_vowel_diacritic')\n","            target.append(vowel_pred[i])\n","            index += 1\n","    \n","    del df_test_img\n","    del X_test_resized\n","    del test_dataset\n","    del test_loader\n","    gc.collect()\n","\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","\n","if create_submission:\n","    df_sample.to_csv('submission.csv',index=False)\n","\n","df_sample.head(36)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Resizing raw image... / 前処理実行中…\n","model loaded from ../trained_models/resnet18.pth\n","model loaded from ../trained_models/efficientnet_28epoch.pth\n","Resizing raw image... / 前処理実行中…\n","model loaded from ../trained_models/resnet18.pth\n","model loaded from ../trained_models/efficientnet_28epoch.pth\n","Resizing raw image... / 前処理実行中…\n","model loaded from ../trained_models/resnet18.pth\n","model loaded from ../trained_models/efficientnet_28epoch.pth\n","Resizing raw image... / 前処理実行中…\n","model loaded from ../trained_models/resnet18.pth\n","model loaded from ../trained_models/efficientnet_28epoch.pth\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test_0_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test_0_grapheme_root</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test_0_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Test_1_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Test_1_grapheme_root</td>\n","      <td>93</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Test_1_vowel_diacritic</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Test_2_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Test_2_grapheme_root</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Test_2_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Test_3_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Test_3_grapheme_root</td>\n","      <td>115</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Test_3_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Test_4_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Test_4_grapheme_root</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Test_4_vowel_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Test_5_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Test_5_grapheme_root</td>\n","      <td>115</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Test_5_vowel_diacritic</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Test_6_consonant_diacritic</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Test_6_grapheme_root</td>\n","      <td>147</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Test_6_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Test_7_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Test_7_grapheme_root</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Test_7_vowel_diacritic</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Test_8_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Test_8_grapheme_root</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Test_8_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Test_9_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Test_9_grapheme_root</td>\n","      <td>133</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Test_9_vowel_diacritic</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Test_10_consonant_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Test_10_grapheme_root</td>\n","      <td>148</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Test_10_vowel_diacritic</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Test_11_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Test_11_grapheme_root</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Test_11_vowel_diacritic</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         row_id  target\n","0    Test_0_consonant_diacritic       0\n","1          Test_0_grapheme_root       3\n","2        Test_0_vowel_diacritic       0\n","3    Test_1_consonant_diacritic       0\n","4          Test_1_grapheme_root      93\n","5        Test_1_vowel_diacritic       2\n","6    Test_2_consonant_diacritic       0\n","7          Test_2_grapheme_root      19\n","8        Test_2_vowel_diacritic       0\n","9    Test_3_consonant_diacritic       0\n","10         Test_3_grapheme_root     115\n","11       Test_3_vowel_diacritic       0\n","12   Test_4_consonant_diacritic       0\n","13         Test_4_grapheme_root      13\n","14       Test_4_vowel_diacritic       4\n","15   Test_5_consonant_diacritic       0\n","16         Test_5_grapheme_root     115\n","17       Test_5_vowel_diacritic       2\n","18   Test_6_consonant_diacritic       5\n","19         Test_6_grapheme_root     147\n","20       Test_6_vowel_diacritic       9\n","21   Test_7_consonant_diacritic       0\n","22         Test_7_grapheme_root     137\n","23       Test_7_vowel_diacritic       7\n","24   Test_8_consonant_diacritic       0\n","25         Test_8_grapheme_root     119\n","26       Test_8_vowel_diacritic       9\n","27   Test_9_consonant_diacritic       0\n","28         Test_9_grapheme_root     133\n","29       Test_9_vowel_diacritic      10\n","30  Test_10_consonant_diacritic       4\n","31        Test_10_grapheme_root     148\n","32      Test_10_vowel_diacritic       1\n","33  Test_11_consonant_diacritic       0\n","34        Test_11_grapheme_root      21\n","35      Test_11_vowel_diacritic       2"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"PloUqk5-nHI9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}