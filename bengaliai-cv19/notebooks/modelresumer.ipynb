{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 諸々の import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score\n",
    "import cv2\n",
    "# from tqdm.auto import tqdm\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import PIL\n",
    "# from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "\n",
    "dataset_dir = '../dataset'\n",
    "# dataset_dir = '/kaggle/input/bengaliai-cv19'\n",
    "train_df = pd.read_csv(dataset_dir + '/train.csv')\n",
    "test_df = pd.read_csv(dataset_dir + '/test.csv')\n",
    "class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')\n",
    "\n",
    "model_dir = '../trained_models'\n",
    "# model_dir = '/kaggle/input/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from model.CNN import model\n",
    "# from model.efficientnet import model\n",
    "# from model.resnet18 import model\n",
    "\n",
    "model = model()\n",
    "model = try_gpu(model)\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "# resize後のサイズ\n",
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "\n",
    "# 画像を3次元にするかどうか（EfficientNetなどを使うときはTrue）\n",
    "enable_3d = True\n",
    "\n",
    "# True なら Cross Validation を実施する\n",
    "# Kaggle に提出するときは False にしてください\n",
    "do_validation = True\n",
    "\n",
    "# True なら submission.csv を生成する\n",
    "create_submission = False\n",
    "\n",
    "val_perc = 0.2  # validation set の割合（クロスバリデーション）\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train関数、test関数\n",
    "\n",
    "def train(model, epoch, train_loader):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, root_l, vowel_l, consonant_l = data\n",
    "        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n",
    "        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n",
    "        optimizer.zero_grad()\n",
    "        root_o, vowel_o, consonant_o = model(inputs)\n",
    "        loss1 = criterion1(root_o, root_l)\n",
    "        loss2 = criterion1(vowel_o, vowel_l)\n",
    "        loss3 = criterion1(consonant_o, consonant_l)\n",
    "        (loss1+loss2+loss3).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    size = len(test_loader.dataset)\n",
    "    pred_r, pred_v, pred_c = np.zeros(size), np.zeros(size), np.zeros(size)\n",
    "    true_r, true_v, true_c = np.zeros(size), np.zeros(size), np.zeros(size)\n",
    "    index = 0\n",
    "    \n",
    "    for data in test_loader:\n",
    "        inputs, root_l, vowel_l, consonant_l = data\n",
    "        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n",
    "        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n",
    "        \n",
    "        root_o, vowel_o, consonant_o = model(inputs) \n",
    "        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n",
    "        for i in range(inputs.size(0)):\n",
    "            pred_r[index] = root_pred[i]\n",
    "            pred_v[index] = vowel_pred[i]\n",
    "            pred_c[index] = consonant_pred[i]\n",
    "            true_r[index] = root_l[i]\n",
    "            true_v[index] = vowel_l[i]\n",
    "            true_c[index] = consonant_l[i]\n",
    "            index += 1\n",
    "\n",
    "    recall_r = recall_score(true_r, pred_r, average='macro')\n",
    "    recall_v = recall_score(true_v, pred_v, average='macro')\n",
    "    recall_c = recall_score(true_c, pred_c, average='macro')\n",
    "    final_score = (2.*recall_r + recall_v + recall_c) / 4.\n",
    "\n",
    "    print(f'Root Recall: {recall_r:.5f}')\n",
    "    print(f'Vowel Recall: {recall_v:.5f}')\n",
    "    print(f'Consonant Recall: {recall_c:.5f}')\n",
    "    print(f'Score: {final_score:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データの読み込み\n",
    "\n",
    "X_all = np.empty((0, HEIGHT*WIDTH))\n",
    "Y_root_all = np.empty((0, 168))\n",
    "Y_vowel_all = np.empty((0, 11))\n",
    "Y_cons_all = np.empty((0, 7))\n",
    "\n",
    "for parq_i in range(4):\n",
    "    print(f'Parquet {parq_i} を読み込み中')\n",
    "    train_df_with_img = pd.merge(pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)\n",
    "    \n",
    "    X = train_df_with_img.drop(columns=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'])\n",
    "    X_resized = resize(X, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8) # astype(np.uint8)をしてあげることで後で cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB) が実行できるようになる\n",
    "    \n",
    "    Y_root = pd.get_dummies(train_df_with_img['grapheme_root']).values\n",
    "    Y_vowel = pd.get_dummies(train_df_with_img['vowel_diacritic']).values\n",
    "    Y_cons = pd.get_dummies(train_df_with_img['consonant_diacritic']).values\n",
    "\n",
    "    X_all = np.append(X_all, X_resized, axis=0)\n",
    "    Y_root_all = np.append(Y_root_all, Y_root, axis=0)\n",
    "    Y_vowel_all = np.append(Y_vowel_all, Y_vowel, axis=0)\n",
    "    Y_cons_all = np.append(Y_cons_all, Y_cons, axis=0)\n",
    "\n",
    "    del X\n",
    "    del X_resized\n",
    "    del Y_root\n",
    "    del Y_vowel \n",
    "    del Y_cons \n",
    "    gc.collect()\n",
    "\n",
    "print(X_all.shape)\n",
    "print(Y_root_all.shape)\n",
    "print(Y_vowel_all.shape)\n",
    "print(Y_cons_all.shape)\n",
    "\n",
    "Y_all = [Y_root_all, Y_vowel_all, Y_cons_all]\n",
    "\n",
    "trainval_dataset = MyDataset(X_all, Y_all, enable_3d=enable_3d, H=HEIGHT, W=WIDTH)\n",
    "\n",
    "del X_all\n",
    "del Y_root_all\n",
    "del Y_vowel_all\n",
    "del Y_cons_all\n",
    "del Y_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
