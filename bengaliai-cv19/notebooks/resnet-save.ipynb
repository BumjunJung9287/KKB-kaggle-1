{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet-save.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMHfn08lTvowJY83ETfAcFa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y2WQPk6wbPZ0","colab_type":"code","outputId":"6dda5b37-f8a7-41f8-d35d-bbbd368c69f9","executionInfo":{"status":"ok","timestamp":1583224353428,"user_tz":-540,"elapsed":22791,"user":{"displayName":"Naoaki Kanazawa","photoUrl":"","userId":"02988158448965055485"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n","Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","[Errno 2] No such file or directory: 'gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks'\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rR2jWobYbUi6","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Om2DiBQQbWMg","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import recall_score\n","import cv2\n","# from tqdm.auto import tqdm\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, ConcatDataset\n","from torchvision import datasets, transforms, utils\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","import PIL\n","# from torchsummary import summary\n","import gc\n","\n","dataset_dir = '../dataset'\n","# dataset_dir = '/kaggle/input/bengaliai-cv19'\n","train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')\n","\n","model_dir = '../model'\n","# model_dir = '/kaggle/input/models'\n","\n","# 前処理を関数にまとめた\n","def resize(X, out_height=64, out_width=64):\n","    print('Resizing raw image... / 前処理実行中…')\n","    # resized = {} # 前処理された画像が格納されるリスト\n","    resized = np.zeros((len(X), out_height * out_width))\n","\n","    for i in range(len(X)):\n","        image = X.iloc[[i]].values.reshape(HEIGHT, WIDTH)\n","        _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","        contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","        left = 1000\n","        right = -1\n","        top = 1000\n","        bottom = -1\n","\n","        for cnt in contours:\n","            x,y,w,h = cv2.boundingRect(cnt)\n","            left = min(x, left)\n","            right = max(x+w, right)\n","            top = min(y, top)\n","            bottom = max(y+h, bottom)\n","\n","        roi = image[top:bottom, left:right]\n","        resized_roi = cv2.resize(roi, (out_height, out_width),interpolation=cv2.INTER_AREA)\n","        resized[i] = resized_roi.reshape(-1)\n","\n","    # print(len(resized))\n","\n","    return resized\n","\n","def try_gpu(e):\n","    if torch.cuda.is_available():\n","        return e.cuda()\n","    return e"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJbfflPibacH","colab_type":"code","colab":{}},"source":["#resnet\n","def conv3x3(in_channels, out_channels, stride=1, groups=1, dilation=1):\n","     return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n","                      padding=dilation, groups=groups, bias=True,\n","                      dilation=dilation)\n","\n","def conv1x1(in_channels, out_channels, stride=1):\n","     return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=True)\n","\n","class BasicBlock(nn.Module):\n","    #Implementation of Basic Building Block\n","\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = conv3x3(in_channels, out_channels, stride)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(out_channels, out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity_x = x  # hold input for shortcut connection\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity_x = self.downsample(x)\n","\n","        out += identity_x  # shortcut connection\n","        return self.relu(out)\n","\n","class ResidualLayer(nn.Module):\n","\n","    def __init__(self, num_blocks, in_channels, out_channels, block=BasicBlock):\n","        super(ResidualLayer, self).__init__()\n","        downsample = None\n","        if in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                conv1x1(in_channels, out_channels),\n","                nn.BatchNorm2d(out_channels))\n","        self.first_block = block(in_channels, out_channels, downsample=downsample)\n","        self.blocks = nn.ModuleList(block(out_channels, out_channels) for _ in range(num_blocks))\n","\n","    def forward(self, x):\n","        out = self.first_block(x)\n","        for block in self.blocks:\n","            out = block(out)\n","        return out\n","\n","class model(nn.Module):\n","    def __init__(self):\n","        #resnet18の実装\n","        super(model, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = ResidualLayer(2, in_channels=64, out_channels=64)\n","        self.layer2 = ResidualLayer(2, in_channels=64, out_channels=128)\n","        self.layer3 = ResidualLayer(2, in_channels=128, out_channels=256)\n","        self.layer4 = ResidualLayer(2, in_channels=256, out_channels=512)\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, 512)\n","\n","        self.head_root = nn.Linear(512, 168) # + softmax\n","        self.head_vowel = nn.Linear(512, 11) # + softmax\n","        self.head_consonant = nn.Linear(512, 7) # + softmax\n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        \n","        head_root = self.head_root(x)\n","        head_vowel = self.head_vowel(x)\n","        head_consonant = self.head_consonant(x)\n","\n","        return head_root, head_vowel, head_consonant # not sure..\n","\n","model = model()\n","model = try_gpu(model)\n","\n","criterion1 = nn.CrossEntropyLoss() \n","#criterion2 = nn.CrossEntropyLoss() \n","#criterion3 = nn.CrossEntropyLoss() \n","optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VhC94tyzbkkt","colab_type":"code","colab":{}},"source":["\n","def train(model, epoch, train_loader):\n","    model.train()\n","    print(f'Epoch number {epoch}')\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        loss1 = criterion1(root_o, root_l)\n","        loss2 = criterion1(vowel_o, vowel_l)\n","        loss3 = criterion1(consonant_o, consonant_l)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","        # if i % 500 == 0:\n","        #     print(\"epoch{} root {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss1.data))\n","        #     print(\"epoch{} vowel {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss2.data))\n","        #     print(\"epoch{} consonant {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss3.data))\n","\n","def test(model, test_loader):\n","    model.eval()\n","\n","    size = len(test_loader.dataset)\n","    pred_r, pred_v, pred_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    true_r, true_v, true_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    index = 0\n","    \n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        \n","        root_o, vowel_o, consonant_o = model(inputs) \n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        for i in range(inputs.size(0)):\n","            pred_r[index] = root_pred[i]\n","            pred_v[index] = vowel_pred[i]\n","            pred_c[index] = consonant_pred[i]\n","            true_r[index] = root_l[i]\n","            true_v[index] = vowel_l[i]\n","            true_c[index] = consonant_l[i]\n","            index += 1\n","\n","    recall_r = recall_score(true_r, pred_r, average='macro')\n","    recall_v = recall_score(true_v, pred_v, average='macro')\n","    recall_c = recall_score(true_c, pred_c, average='macro')\n","    final_score = (2.*recall_r + recall_v + recall_c) / 4.\n","\n","    print(f'Root Recall: {recall_r:.5f}')\n","    print(f'Vowel Recall: {recall_v:.5f}')\n","    print(f'Consonant Recall: {recall_c:.5f}')\n","    print(f'Score: {final_score:.5f}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ui-C4yyJb9Rb","colab_type":"code","colab":{}},"source":["# Augmentation のための transform を定義\n","\n","transform_crop = transforms.Compose([\n","                                transforms.ToPILImage(),\n","                                transforms.RandomResizedCrop((64,64), scale=(0.80, 0.90)),\n","                                transforms.ToTensor()\n","])\n","\n","\n","rotate_left = transforms.RandomAffine((-20, -10), fillcolor=255, resample=PIL.Image.BILINEAR)\n","rotate_right = transforms.RandomAffine((10, 20), fillcolor=255, resample=PIL.Image.BILINEAR)\n","transform_rotate = transforms.Compose([\n","                                       transforms.ToPILImage(),\n","                                       transforms.RandomChoice([rotate_left, rotate_right]),\n","                                       transforms.ToTensor()\n","])\n","\n","\n","class AddGaussianNoise(object):\n","    def __init__(self, mean=0., std=1.):\n","        self.std = std\n","        self.mean = mean\n","        \n","    def __call__(self, tensor):\n","        with_noise = tensor + torch.randn(tensor.size()) * self.std + self.mean\n","        return torch.max(torch.min(with_noise, torch.tensor(1.)), torch.tensor(0.))\n","    \n","    def __repr__(self):\n","        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n","\n","transform_noise = AddGaussianNoise(0., 0.01)\n","\n","\n","# PyTorch式のデータセットクラスを定義\n","\n","class MyDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, X, Y, transform=None):\n","        self.transform = transform\n","        self.X = X\n","        self.Y = Y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        out_data = self.X[idx].reshape(1,64,64)\n","        out_data = torch.tensor(out_data, dtype=torch.float)\n","\n","        #root_label = torch.tensor(self.Y[0][idx], dtype=torch.long)\n","        #vowel_label = torch.tensor(self.Y[1][idx], dtype=torch.long)\n","        #cons_label = torch.tensor(self.Y[2][idx], dtype=torch.long)\n","\n","        root_label = torch.tensor(np.argmax(self.Y[0][idx]), dtype=torch.long)\n","        vowel_label = torch.tensor(np.argmax(self.Y[1][idx]), dtype=torch.long)\n","        cons_label = torch.tensor(np.argmax(self.Y[2][idx]), dtype=torch.long)\n","\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","\n","        return out_data, root_label, vowel_label, cons_label\n","\n","\n","class MakeSubset(torch.utils.data.Dataset):\n","\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        out_data, root_label, vowel_label, cons_label = self.dataset[idx]\n","\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","\n","        return out_data, root_label, vowel_label, cons_label\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mj6oj_WOevTi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHB6zYCncGUA","colab_type":"code","outputId":"7ac5cc1d-ea2d-4691-ee85-f018271c0e8a","colab":{"base_uri":"https://localhost:8080/","height":647},"executionInfo":{"status":"ok","timestamp":1583233044811,"user_tz":-540,"elapsed":2877907,"user":{"displayName":"Naoaki Kanazawa","photoUrl":"","userId":"02988158448965055485"}}},"source":["# 訓練ループ / Training Loop\n","\n","###############\n","# True なら Cross Validation を実施する\n","# Kaggle に提出するときは False にしてください\n","do_validation = False\n","\n","# True なら submission.csv を生成する\n","create_submission = False\n","\n","val_perc = 0.2  # validation set の割合（クロスバリデーション）\n","epochs = 5\n","\n","###############\n","\n","for parq_i in range(4):\n","    print('=============================')\n","    print(f'Parquet {parq_i} の訓練を開始')\n","\n","    train_df_with_img = pd.merge(pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)\n","\n","    HEIGHT = 137\n","    WIDTH = 236\n","\n","    X_train = train_df_with_img.drop(columns=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'])\n","\n","    # X_train_resized = pd.DataFrame(resize(X_train)).T / 255.0   # 値を0~1におさめる\n","    # X_train_resized = X_train_resized.values\n","    X_train_resized = resize(X_train) / 255.0\n","\n","    # メモリ節約\n","    del X_train\n","\n","    # PyTorchのデータセットクラスを作る前に、ラベルの情報も整備\n","    # 1-of-K符号化とか、One Hot Encodingとか呼ばれる方法でラベルをつくる\n","\n","    # 注：　PyTorchでは、ラベルはOne Hotじゃなくて良いことが判明したので、結局 MyDataset で元のラベルに戻している\n","\n","    Y_train_root = pd.get_dummies(train_df_with_img['grapheme_root']).values\n","    Y_train_vowel = pd.get_dummies(train_df_with_img['vowel_diacritic']).values\n","    Y_train_cons = pd.get_dummies(train_df_with_img['consonant_diacritic']).values\n","\n","    Y_train = [Y_train_root, Y_train_vowel, Y_train_cons]\n","\n","    trainval_dataset = MyDataset(X_train_resized, Y_train)\n","\n","    del X_train_resized\n","    del train_df_with_img\n","    gc.collect()\n","\n","    if do_validation:\n","        n_samples = len(trainval_dataset)\n","        train_size = int(len(trainval_dataset)*(1.0 - val_perc))\n","        val_size = n_samples - train_size\n","        print(f'train size: {train_size}, validation size: {val_size}')\n","\n","        train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n","\n","        train_subset1 = MakeSubset(train_dataset)\n","        train_subset2 = MakeSubset(train_dataset, transform=transform_crop)\n","        train_subset3 = MakeSubset(train_dataset, transform=transform_rotate)\n","        train_subset4 = MakeSubset(train_dataset, transform=transform_noise)\n","\n","        del trainval_dataset\n","        del train_dataset\n","        gc.collect()\n","\n","        aug_dataset = ConcatDataset([train_subset1, train_subset2, train_subset3, train_subset4])\n","        \n","        del train_subset1, train_subset2, train_subset3, train_subset4\n","        gc.collect()\n","\n","        train_loader = DataLoader(dataset=aug_dataset, batch_size=32, shuffle=True, num_workers=4)\n","        val_loader = DataLoader(dataset=val_dataset, batch_size=32, num_workers=4)\n","        print(f'train size (after augmentation): {len(aug_dataset)}, validation size: {len(val_dataset)}')\n","\n","        for i in range(1,epochs+1):\n","            train(model, i, train_loader)\n","            test(model, val_loader)\n","\n","        # メモリ節約\n","        del aug_dataset\n","        del val_dataset\n","        del train_loader\n","        del val_loader\n","        gc.collect()\n","\n","    else:\n","        train_subset1 = MakeSubset(trainval_dataset)\n","        train_subset2 = MakeSubset(trainval_dataset, transform=transform_crop)\n","        train_subset3 = MakeSubset(trainval_dataset, transform=transform_rotate)\n","        train_subset4 = MakeSubset(trainval_dataset, transform=transform_noise)\n","\n","        del trainval_dataset\n","        gc.collect()\n","\n","        aug_dataset = ConcatDataset([train_subset1, train_subset2, train_subset3, train_subset4])\n","        \n","        del train_subset1, train_subset2, train_subset3, train_subset4\n","        gc.collect()\n","\n","        train_loader = DataLoader(dataset=aug_dataset, batch_size=32, shuffle=True, num_workers=4)\n","        print(f'train size (after augmentation): {len(aug_dataset)}')\n","\n","        for i in range(1,epochs+1):\n","            train(model, i, train_loader)\n","\n","        # メモリ節約\n","        del aug_dataset\n","        del train_loader\n","        gc.collect()\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["=============================\n","Parquet 0 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","train size (after augmentation): 200840\n","Epoch number 1\n","Epoch number 2\n","Epoch number 3\n","Epoch number 4\n","Epoch number 5\n","=============================\n","Parquet 1 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","train size (after augmentation): 200840\n","Epoch number 1\n","Epoch number 2\n","Epoch number 3\n","Epoch number 4\n","Epoch number 5\n","=============================\n","Parquet 2 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","train size (after augmentation): 200840\n","Epoch number 1\n","Epoch number 2\n","Epoch number 3\n","Epoch number 4\n","Epoch number 5\n","=============================\n","Parquet 3 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","train size (after augmentation): 200840\n","Epoch number 1\n","Epoch number 2\n","Epoch number 3\n","Epoch number 4\n","Epoch number 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OJqxbfevcb-r","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), model_dir + '/resnet_5epochs_saved_weights.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTinGv8qhp-6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"63d9a4bd-73c0-4648-9838-3c808ab01a14","executionInfo":{"status":"ok","timestamp":1583233201457,"user_tz":-540,"elapsed":12656,"user":{"displayName":"Naoaki Kanazawa","photoUrl":"","userId":"02988158448965055485"}}},"source":["\n","# True なら submission.csv を生成する\n","create_submission = False\n","\n","HEIGHT = 137\n","WIDTH = 236\n","\n","# 提出ファイルの準備\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","for parq_i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","    # df_test_img = pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet') # Error Check!\n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    # X_test_resized = resize(df_test_img)\n","    # X_test_resized = pd.DataFrame(X_test_resized).T / 255.0   # 値を0~1におさめる\n","    # X_test_resized = X_test_resized.values.reshape(-1, 1, 64, 64)\n","\n","    X_test_resized = resize(df_test_img).reshape(-1, 1, 64, 64) / 255.0\n","\n","    test_inputs = torch.tensor(X_test_resized, dtype=torch.float)\n","    test_inputs = Variable(test_inputs)\n","    test_inputs = try_gpu(test_inputs)\n","\n","    del X_test_resized\n","    gc.collect()\n","    \n","# テストデータをいっぺんに入れるとメモリが足りないので変更！\n","#     root_o, vowel_o, consonant_o = model(test_inputs)\n","#     root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","#     if torch.cuda.is_available():\n","#         root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","#\n","#     root_pred, vowel_pred, consonant_pred = root_pred.numpy(), vowel_pred.numpy(), consonant_pred.numpy()\n","#\n","#     for k, id in enumerate(df_test_img.index.values):\n","#         row_id.append(id+'_consonant_diacritic')\n","#         target.append(consonant_pred[k])\n","#         row_id.append(id+'_grapheme_root')\n","#         target.append(root_pred[k])\n","#         row_id.append(id+'_vowel_diacritic')\n","#         target.append(vowel_pred[k])\n","\n","    for k, id in enumerate(df_test_img.index.values):\n","        data = test_inputs[k].reshape(1,1,64,64)\n","        root_o, vowel_o, consonant_o = model(data)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        if torch.cuda.is_available():\n","            root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","\n","        root_pred, vowel_pred, consonant_pred = root_pred.item(), vowel_pred.item(), consonant_pred.item()\n","        \n","        row_id.append(id+'_consonant_diacritic')\n","        target.append(consonant_pred)\n","        row_id.append(id+'_grapheme_root')\n","        target.append(root_pred)\n","        row_id.append(id+'_vowel_diacritic')\n","        target.append(vowel_pred)\n","    \n","    del df_test_img\n","    gc.collect()\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","\n","if create_submission:\n","    df_sample.to_csv('submission.csv',index=False)\n","\n","df_sample.head(36)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test_0_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test_0_grapheme_root</td>\n","      <td>148</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test_0_vowel_diacritic</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Test_1_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Test_1_grapheme_root</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Test_1_vowel_diacritic</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Test_2_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Test_2_grapheme_root</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Test_2_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Test_3_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Test_3_grapheme_root</td>\n","      <td>96</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Test_3_vowel_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Test_4_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Test_4_grapheme_root</td>\n","      <td>91</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Test_4_vowel_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Test_5_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Test_5_grapheme_root</td>\n","      <td>148</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Test_5_vowel_diacritic</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Test_6_consonant_diacritic</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Test_6_grapheme_root</td>\n","      <td>147</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Test_6_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Test_7_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Test_7_grapheme_root</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Test_7_vowel_diacritic</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Test_8_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Test_8_grapheme_root</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Test_8_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Test_9_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Test_9_grapheme_root</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Test_9_vowel_diacritic</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Test_10_consonant_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Test_10_grapheme_root</td>\n","      <td>148</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Test_10_vowel_diacritic</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Test_11_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Test_11_grapheme_root</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Test_11_vowel_diacritic</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         row_id  target\n","0    Test_0_consonant_diacritic       0\n","1          Test_0_grapheme_root     148\n","2        Test_0_vowel_diacritic       3\n","3    Test_1_consonant_diacritic       0\n","4          Test_1_grapheme_root      51\n","5        Test_1_vowel_diacritic       3\n","6    Test_2_consonant_diacritic       0\n","7          Test_2_grapheme_root      19\n","8        Test_2_vowel_diacritic       0\n","9    Test_3_consonant_diacritic       0\n","10         Test_3_grapheme_root      96\n","11       Test_3_vowel_diacritic       4\n","12   Test_4_consonant_diacritic       0\n","13         Test_4_grapheme_root      91\n","14       Test_4_vowel_diacritic       4\n","15   Test_5_consonant_diacritic       0\n","16         Test_5_grapheme_root     148\n","17       Test_5_vowel_diacritic       3\n","18   Test_6_consonant_diacritic       5\n","19         Test_6_grapheme_root     147\n","20       Test_6_vowel_diacritic       9\n","21   Test_7_consonant_diacritic       0\n","22         Test_7_grapheme_root      51\n","23       Test_7_vowel_diacritic       7\n","24   Test_8_consonant_diacritic       0\n","25         Test_8_grapheme_root      44\n","26       Test_8_vowel_diacritic       9\n","27   Test_9_consonant_diacritic       0\n","28         Test_9_grapheme_root     150\n","29       Test_9_vowel_diacritic       3\n","30  Test_10_consonant_diacritic       4\n","31        Test_10_grapheme_root     148\n","32      Test_10_vowel_diacritic       1\n","33  Test_11_consonant_diacritic       0\n","34        Test_11_grapheme_root      51\n","35      Test_11_vowel_diacritic       3"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"KhW5IA6bC6Jv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}